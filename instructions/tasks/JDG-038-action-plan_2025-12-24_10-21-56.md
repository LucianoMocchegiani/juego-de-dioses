# JDG-038 - Fase 1: Fundación del Sistema de Partículas

## Descripción de la Tarea

Implementar la fundación completa del sistema de partículas, incluyendo la estructura de base de datos, sistema de bloques unificado y funciones auxiliares básicas. Esta fase establece las bases para todas las demás fases del sistema de partículas.

**Comportamiento actual:**
- Existe estructura básica de partículas pero no completa según diseño final
- Tabla `dimensiones` existe en schema inicial
- Faltan funciones auxiliares básicas
- No existe sistema unificado de bloques

**Comportamiento esperado:**
- Schema inicial (`01-init-schema.sql`) actualizado con todas las tablas y campos del diseño final
- Tabla `dimensiones` reemplazada por `bloques` en schema inicial
- Tabla `particulas` usa `bloque_id` desde el inicio (no `dimension_id`)
- Al reconstruir Docker, todo debe crearse correctamente desde el schema inicial
- Sistema de bloques unificado funcionando
- Funciones auxiliares básicas implementadas
- Base sólida para fases siguientes

## Criterios de Aceptación

1. ✅ Tabla `tipos_particulas` actualizada en schema inicial con todos los campos del diseño final
2. ✅ Tabla `particulas` actualizada en schema inicial con todos los campos del diseño final
3. ✅ Tabla `transiciones_particulas` agregada al schema inicial
4. ✅ Tabla `dimensiones` reemplazada por `bloques` en schema inicial con `tamano_bloque`
5. ✅ Tabla `particulas` usa `bloque_id` desde el schema inicial (no `dimension_id`)
6. ✅ Clases `WorldBloque` y `WorldBloqueManager` implementadas
7. ✅ Funciones auxiliares básicas implementadas
8. ✅ Schema inicial completo y funcional (sin migraciones)
9. ✅ Índices creados en schema inicial para optimización
10. ✅ READMEs actualizados

## Contexto del Proyecto

### Proyecto(s) Afectado(s)
- [x] Backend (FastAPI)
- [ ] Frontend (Three.js)
- [x] Base de Datos (PostgreSQL)
- [ ] Cache (Redis)
- [ ] Docker/Infraestructura

### Tecnologías Involucradas
- Backend: Python 3.11, FastAPI, Uvicorn, asyncpg
- Base de datos: PostgreSQL 16
- Migraciones: SQL scripts
- Validación: Pydantic models

## Pasos de Implementación

### Paso 1: Actualizar Tabla tipos_particulas en Schema Inicial

**Descripción:**
Actualizar la definición de la tabla `tipos_particulas` en el schema inicial para incluir todos los campos del diseño final: `integridad`, `conductividad_electrica`, `magnetismo`, `tipo_fisico`, y todas las propiedades específicas por tipo físico.

**Archivos a modificar/crear:**
- `database/init/01-init-schema.sql` (actualizar definición completa de `tipos_particulas`)
- `backend/src/models/schemas.py` (crear modelos Pydantic)

**Detalles de implementación:**
```sql
-- Reemplazar la definición de tipos_particulas con la versión completa
CREATE TABLE IF NOT EXISTS tipos_particulas (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    nombre VARCHAR(100) NOT NULL UNIQUE,
    
    -- Tipo físico (determina qué propiedades usar)
    tipo_fisico VARCHAR(50) NOT NULL DEFAULT 'solido',  -- 'solido', 'liquido', 'gas', 'energia'
    
    -- ===== PROPIEDADES COMUNES (Todos los tipos) =====
    densidad DECIMAL(3,2) DEFAULT 1.0,              -- 0.0 a 10.0 (0 = no gravedad)
    conductividad_termica DECIMAL(3,2) DEFAULT 1.0, -- 0.0 a 10.0 (propagación de calor)
    calor_especifico DECIMAL(3,2) DEFAULT 1.0,      -- 0.0 a 10.0 (cambio de temperatura)
    opacidad DECIMAL(3,2) DEFAULT 1.0,             -- 0.0 (transparente) a 1.0 (opaco)
    color VARCHAR(50),
    geometria JSONB DEFAULT '{"tipo": "box"}',
    
    -- ===== PROPIEDADES ELÉCTRICAS Y MAGNÉTICAS (Todos los tipos) =====
    conductividad_electrica DECIMAL(3,2) DEFAULT 0.0, -- 0.0 a 10.0 (capacidad de conducir electricidad)
    magnetismo DECIMAL(3,2) DEFAULT 0.0,            -- 0.0 a 10.0 (fuerza magnética)
    integridad DECIMAL(3,2) DEFAULT 1.0,           -- 0.0 a 1.0 (durabilidad/vida)
    
    -- ===== PROPIEDADES DE SÓLIDOS =====
    dureza DECIMAL(3,2),              -- 0.0 a 10.0 (NULL si no es sólido)
    fragilidad DECIMAL(3,2),          -- 0.0 a 10.0 (NULL si no es sólido)
    elasticidad DECIMAL(3,2),         -- 0.0 a 10.0 (NULL si no es sólido)
    punto_fusion DECIMAL(10,2),       -- Temperatura en °C (NULL si no se derrite)
    
    -- ===== PROPIEDADES DE LÍQUIDOS =====
    viscosidad DECIMAL(3,2),          -- 0.0 a 10.0 (NULL si no es líquido)
    punto_ebullicion DECIMAL(10,2),   -- Temperatura en °C (NULL si no se evapora)
    
    -- ===== PROPIEDADES DE GASES/ENERGÍA =====
    propagacion DECIMAL(3,2),         -- 0.0 a 10.0 (NULL si no es gas/energía)
    
    -- Propiedades avanzadas (opcionales)
    propiedades_fisicas JSONB DEFAULT '{}',
    
    -- Metadatos
    descripcion TEXT,
    creado_en TIMESTAMP DEFAULT NOW()
);

-- Índices para consultas eficientes
CREATE INDEX IF NOT EXISTS idx_tipos_particulas_nombre ON tipos_particulas(nombre);
CREATE INDEX IF NOT EXISTS idx_tipos_particulas_tipo_fisico ON tipos_particulas(tipo_fisico);
CREATE INDEX IF NOT EXISTS idx_tipos_particulas_conductividad_electrica 
ON tipos_particulas(conductividad_electrica) WHERE conductividad_electrica > 0;
```

**Notas:**
- Reemplazar completamente la definición anterior de `tipos_particulas` en el schema inicial
- Asegurar que todos los campos estén presentes desde el inicio
- **⚠️ READMEs:** Actualizar `database/README.md` si existe, documentar cambios en esquema

**Recursos útiles:**
- `Juego de Dioses/Ideas/29-Diseno-Final-Particulas.md` - Diseño completo

---

### Paso 2: Actualizar Tabla particulas en Schema Inicial

**Descripción:**
Actualizar la definición de la tabla `particulas` en el schema inicial para incluir todos los campos del diseño final: `integridad`, `carga_electrica`, `temperatura`, y cambiar la referencia de `dimension_id` a `bloque_id`.

**Archivos a modificar/crear:**
- `database/init/01-init-schema.sql` (actualizar definición completa de `particulas`)
- `backend/src/models/schemas.py` (actualizar modelos)

**Detalles de implementación:**
```sql
-- Reemplazar la definición de particulas con la versión completa
CREATE TABLE IF NOT EXISTS particulas (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    bloque_id UUID NOT NULL REFERENCES bloques(id) ON DELETE CASCADE,
    
    -- Posición 3D
    celda_x INTEGER NOT NULL,
    celda_y INTEGER NOT NULL,
    celda_z INTEGER NOT NULL,
    
    -- Tipo y estado
    tipo_particula_id UUID NOT NULL REFERENCES tipos_particulas(id),
    
    -- Propiedades dinámicas
    temperatura DECIMAL(10,2) DEFAULT 20.0,
    integridad DECIMAL(3,2) DEFAULT 1.0,           -- 0.0 a 1.0 (durabilidad/vida)
    carga_electrica DECIMAL(5,2) DEFAULT 0.0,     -- -100.0 a +100.0
    
    -- Metadatos
    creado_por UUID,
    creado_en TIMESTAMP DEFAULT NOW(),
    modificado_en TIMESTAMP DEFAULT NOW(),
    
    -- Constraint único por posición
    UNIQUE(bloque_id, celda_x, celda_y, celda_z)
);

-- Índices para consultas frecuentes
CREATE INDEX IF NOT EXISTS idx_particulas_bloque ON particulas(bloque_id);
CREATE INDEX IF NOT EXISTS idx_particulas_tipo ON particulas(tipo_particula_id);
CREATE INDEX IF NOT EXISTS idx_particulas_posicion ON particulas(bloque_id, celda_x, celda_y, celda_z);
CREATE INDEX IF NOT EXISTS idx_particulas_temperatura ON particulas(temperatura);
CREATE INDEX IF NOT EXISTS idx_particulas_integridad 
ON particulas(integridad) WHERE integridad < 1.0;
CREATE INDEX IF NOT EXISTS idx_particulas_carga_electrica 
ON particulas(carga_electrica) WHERE ABS(carga_electrica) > 0;
```

**Notas:**
- Reemplazar completamente la definición anterior de `particulas` en el schema inicial
- Usar `bloque_id` en lugar de `dimension_id` desde el inicio
- Los índices parciales optimizan consultas de partículas con propiedades anómalas
- **⚠️ READMEs:** Documentar nuevos campos en esquema

---

### Paso 3: Agregar Tabla transiciones_particulas al Schema Inicial

**Descripción:**
Agregar la tabla `transiciones_particulas` al schema inicial para manejar las transiciones de estado de las partículas basadas en temperatura e integridad.

**Archivos a modificar/crear:**
- `database/init/01-init-schema.sql` (agregar definición de `transiciones_particulas`)
- `backend/src/models/schemas.py` (crear modelo)

**Detalles de implementación:**
```sql
CREATE TABLE IF NOT EXISTS transiciones_particulas (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tipo_origen_id UUID NOT NULL REFERENCES tipos_particulas(id) ON DELETE CASCADE,
    tipo_destino_id UUID NOT NULL REFERENCES tipos_particulas(id) ON DELETE CASCADE,
    
    -- Condiciones de temperatura
    condicion_temperatura VARCHAR(10), -- 'mayor', 'menor', 'igual'
    valor_temperatura DECIMAL(10,2),
    
    -- Condiciones de integridad
    condicion_integridad VARCHAR(10), -- 'mayor', 'menor', 'igual'
    valor_integridad DECIMAL(3,2),
    
    -- Prioridad (mayor = más importante)
    prioridad INTEGER DEFAULT 0,
    
    -- Estado
    activa BOOLEAN DEFAULT true,
    
    -- Metadatos
    descripcion TEXT,
    creado_en TIMESTAMP DEFAULT NOW(),
    
    -- Constraints
    CHECK (condicion_temperatura IN ('mayor', 'menor', 'igual', NULL)),
    CHECK (condicion_integridad IN ('mayor', 'menor', 'igual', NULL))
);

CREATE INDEX idx_transiciones_origen ON transiciones_particulas(tipo_origen_id);
CREATE INDEX idx_transiciones_destino ON transiciones_particulas(tipo_destino_id);
CREATE INDEX idx_transiciones_activa ON transiciones_particulas(activa) WHERE activa = true;
```

**Notas:**
- Esta tabla es fundamental para el sistema de transiciones de estado
- La prioridad permite resolver conflictos cuando múltiples transiciones son posibles
- **⚠️ READMEs:** Documentar sistema de transiciones

---

### Paso 4: Reemplazar Tabla dimensiones por bloques en Schema Inicial

**Descripción:**
Reemplazar la tabla `dimensiones` por `bloques` en el schema inicial, incluyendo el campo `tamano_bloque` desde el inicio.

**Archivos a modificar/crear:**
- `database/init/01-init-schema.sql` (reemplazar `dimensiones` por `bloques`)
- `backend/src/database/connection.py` (actualizar queries si es necesario)

**Detalles de implementación:**
```sql
-- Reemplazar completamente dimensiones por bloques
CREATE TABLE IF NOT EXISTS bloques (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    nombre VARCHAR(255) DEFAULT 'Mundo Inicial',
    
    -- Límites horizontales (X, Y) en METROS
    ancho_metros DECIMAL(10,2) DEFAULT 1.0,
    alto_metros DECIMAL(10,2) DEFAULT 1.0,
    
    -- Límites verticales (Z) en CELDAS
    profundidad_maxima INTEGER DEFAULT -100,
    altura_maxima INTEGER DEFAULT 100,
    
    -- Tamaño de celda en METROS
    tamano_celda DECIMAL(5,2) DEFAULT 0.25,
    
    -- Posición del origen
    origen_x DECIMAL(10,2) DEFAULT 0.0,
    origen_y DECIMAL(10,2) DEFAULT 0.0,
    origen_z INTEGER DEFAULT 0,
    
    -- ===== CONFIGURACIÓN DE BLOQUES =====
    tamano_bloque INTEGER NOT NULL DEFAULT 40,  -- Tamaño de bloque (40x40x40 celdas)
    
    -- Metadatos
    creado_por UUID,
    creado_en TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_bloques_creado ON bloques(creado_en);

-- Comentario
COMMENT ON COLUMN bloques.tamano_bloque IS 
'Tamaño de bloque en celdas (40x40x40 = 64,000 celdas por bloque). Se usa para dividir el mundo en zonas para temperatura, renderizado y comunicación.';
```

**Notas:**
- Eliminar completamente la definición de `dimensiones` del schema inicial
- Crear `bloques` directamente con todos los campos necesarios
- **⚠️ READMEs:** Actualizar documentación de esquema

---

### Paso 5: Implementar Clase WorldBloque

**Descripción:**
Crear la clase `WorldBloque` en Python que representa un bloque espacial en memoria con sus propiedades de temperatura y partículas asociadas.

**Archivos a modificar/crear:**
- `backend/src/services/world_bloque.py` (crear)
- `backend/src/models/schemas.py` (crear modelo Pydantic si es necesario)

**Detalles de implementación:**
```python
from typing import Set, Optional
from datetime import datetime

class WorldBloque:
    """Representa un bloque espacial del mundo en memoria."""
    
    def __init__(
        self,
        bloque_id: str,
        bloque_x: int,
        bloque_y: int,
        bloque_z: int,
        tamano_bloque: int = 40
    ):
        self.bloque_id = bloque_id  # ID de configuración (de tabla bloques)
        self.bloque_x = bloque_x
        self.bloque_y = bloque_y
        self.bloque_z = bloque_z
        self.tamano_bloque = tamano_bloque
        
        # Partículas en este bloque
        self.particulas: Set[str] = set()  # IDs de partículas
        
        # Temperatura
        self.temperatura_base = 20.0
        self.modificador_altitud = 0.0
        self.modificador_agua = 0.0
        self.modificador_albedo = 0.0
        self.ultima_actualizacion_temperatura = datetime.now()
        self.necesita_recalcular_temperatura = False
        
        # Eventos activos
        self.eventos_activos: Set[str] = set()
        
        # Jugadores en este bloque
        self.jugadores: Set[str] = set()
        
        # Renderizado
        self.needs_rerender = False
    
    async def calcular_temperatura(self, celestial_system) -> None:
        """Calcula la temperatura del bloque basándose en factores ambientales."""
        centro_x = self.bloque_x * self.tamano_bloque + (self.tamano_bloque / 2)
        centro_y = self.bloque_y * self.tamano_bloque + (self.tamano_bloque / 2)
        centro_z = self.bloque_z * self.tamano_bloque + (self.tamano_bloque / 2)
        
        # Temperatura solar
        temp_solar = celestial_system.get_temperature_at(centro_x, centro_y)
        
        # Modificadores (implementar funciones auxiliares)
        from .temperature_helpers import (
            get_altitude_modifier,
            get_water_modifier,
            get_albedo_modifier
        )
        
        self.modificador_altitud = get_altitude_modifier(centro_z)
        self.modificador_agua = await get_water_modifier(centro_x, centro_y, centro_z, self)
        self.modificador_albedo = await get_albedo_modifier(centro_x, centro_y, centro_z, self)
        
        # Temperatura final
        self.temperatura_base = (
            temp_solar + 
            self.modificador_altitud + 
            self.modificador_agua + 
            self.modificador_albedo
        )
        
        self.ultima_actualizacion_temperatura = datetime.now()
        self.necesita_recalcular_temperatura = False
    
    def get_temperatura(self) -> float:
        """Retorna la temperatura base del bloque."""
        return self.temperatura_base
    
    def get_key(self) -> str:
        """Retorna la clave única del bloque."""
        return f"{self.bloque_id}-{self.bloque_x}-{self.bloque_y}-{self.bloque_z}"
```

**Notas:**
- Esta clase se mantiene en memoria para rendimiento
- Los métodos de temperatura se implementarán en fases siguientes
- **⚠️ READMEs:** Crear `backend/src/services/README.md` documentando el servicio

---

### Paso 6: Implementar Clase WorldBloqueManager

**Descripción:**
Crear la clase `WorldBloqueManager` que gestiona los bloques espaciales en memoria, proporcionando métodos para obtener bloques por posición y partícula.

**Archivos a modificar/crear:**
- `backend/src/services/world_bloque_manager.py` (crear)
- `backend/src/services/__init__.py` (exportar clases)

**Detalles de implementación:**
```python
from typing import Dict, Optional
from .world_bloque import WorldBloque
from ..database.connection import get_connection

class WorldBloqueManager:
    """Gestiona bloques espaciales del mundo en memoria."""
    
    def __init__(self):
        self.bloques: Dict[str, WorldBloque] = {}  # key: "bloqueId-bloqueX-bloqueY-bloqueZ"
        self.bloque_configs: Dict[str, dict] = {}  # Cache de configuraciones
    
    async def get_bloque_config(self, bloque_id: str) -> dict:
        """Obtiene configuración de bloque desde BD (con cache)."""
        if bloque_id not in self.bloque_configs:
            async with get_connection() as conn:
                row = await conn.fetchrow(
                    "SELECT * FROM bloques WHERE id = $1",
                    bloque_id
                )
                if row:
                    self.bloque_configs[bloque_id] = dict(row)
        return self.bloque_configs.get(bloque_id)
    
    async def get_bloque_for_position(
        self,
        bloque_id: str,
        celda_x: int,
        celda_y: int,
        celda_z: int
    ) -> WorldBloque:
        """Obtiene bloque espacial para una posición de celda."""
        config = await self.get_bloque_config(bloque_id)
        tamano_bloque = config.get('tamano_bloque', 40) if config else 40
        
        bloque_x = celda_x // tamano_bloque
        bloque_y = celda_y // tamano_bloque
        bloque_z = celda_z // tamano_bloque
        
        key = f"{bloque_id}-{bloque_x}-{bloque_y}-{bloque_z}"
        
        if key not in self.bloques:
            bloque = WorldBloque(
                bloque_id,
                bloque_x,
                bloque_y,
                bloque_z,
                tamano_bloque
            )
            self.bloques[key] = bloque
        
        return self.bloques[key]
    
    async def get_bloque_for_particle(self, particula: dict) -> WorldBloque:
        """Obtiene bloque para una partícula."""
        return await self.get_bloque_for_position(
            particula['bloque_id'],
            particula['celda_x'],
            particula['celda_y'],
            particula['celda_z']
        )
```

**Notas:**
- El manager mantiene cache en memoria para rendimiento
- Los bloques se crean bajo demanda (lazy loading)
- **⚠️ READMEs:** Actualizar `backend/src/services/README.md`

---

### Paso 7: Implementar Funciones Auxiliares Básicas

**Descripción:**
Implementar las funciones auxiliares básicas para consultar partículas y tipos de partículas desde la base de datos.

**Archivos a modificar/crear:**
- `backend/src/services/particula_service.py` (crear)
- `backend/src/services/__init__.py` (exportar funciones)

**Detalles de implementación:**
```python
from typing import Optional, List
from ..database.connection import get_connection

async def get_particula(particula_id: str) -> Optional[dict]:
    """Obtiene una partícula por ID."""
    async with get_connection() as conn:
        row = await conn.fetchrow(
            """
            SELECT p.*, tp.nombre as tipo_nombre, tp.tipo_fisico
            FROM particulas p
            JOIN tipos_particulas tp ON p.tipo_particula_id = tp.id
            WHERE p.id = $1
            """,
            particula_id
        )
        return dict(row) if row else None

async def get_tipo_particula(tipo_id: str) -> Optional[dict]:
    """Obtiene un tipo de partícula por ID."""
    async with get_connection() as conn:
        row = await conn.fetchrow(
            "SELECT * FROM tipos_particulas WHERE id = $1",
            tipo_id
        )
        return dict(row) if row else None

async def get_particulas_vecinas(
    bloque_id: str,
    celda_x: int,
    celda_y: int,
    celda_z: int,
    radio: int = 1
) -> List[dict]:
    """Obtiene partículas vecinas dentro de un radio."""
    async with get_connection() as conn:
        rows = await conn.fetch(
            """
            SELECT p.*, tp.nombre as tipo_nombre
            FROM particulas p
            JOIN tipos_particulas tp ON p.tipo_particula_id = tp.id
            WHERE p.bloque_id = $1
            AND ABS(p.celda_x - $2) <= $5
            AND ABS(p.celda_y - $3) <= $5
            AND ABS(p.celda_z - $4) <= $5
            AND (
                (p.celda_x - $2)^2 + 
                (p.celda_y - $3)^2 + 
                (p.celda_z - $4)^2
            ) <= $5^2
            """,
            bloque_id, celda_x, celda_y, celda_z, radio
        )
        return [dict(row) for row in rows]
```

**Notas:**
- Usar consultas parametrizadas para seguridad
- Optimizar consultas con índices apropiados
- **⚠️ READMEs:** Documentar funciones en `backend/src/services/README.md`

---

### Paso 8: Crear Modelos Pydantic

**Descripción:**
Crear modelos Pydantic para validación y serialización de partículas, tipos de partículas y bloques.

**Archivos a modificar/crear:**
- `backend/src/models/particula_schemas.py` (crear)
- `backend/src/models/__init__.py` (exportar modelos)

**Detalles de implementación:**
```python
from pydantic import BaseModel, Field
from typing import Optional
from datetime import datetime
from decimal import Decimal

class TipoParticulaBase(BaseModel):
    nombre: str
    tipo_fisico: str = Field(..., pattern="^(solido|liquido|gas|energia)$")
    densidad: Decimal = Field(default=Decimal("1.0"), ge=0, le=10)
    conductividad_termica: Decimal = Field(default=Decimal("1.0"), ge=0, le=10)
    calor_especifico: Decimal = Field(default=Decimal("1.0"), ge=0, le=10)
    opacidad: Decimal = Field(default=Decimal("1.0"), ge=0, le=1)
    color: Optional[str] = None
    conductividad_electrica: Decimal = Field(default=Decimal("0.0"), ge=0, le=10)
    magnetismo: Decimal = Field(default=Decimal("0.0"), ge=0, le=10)

class TipoParticulaCreate(TipoParticulaBase):
    pass

class TipoParticula(TipoParticulaBase):
    id: str
    creado_en: datetime
    
    class Config:
        from_attributes = True

class ParticulaBase(BaseModel):
    bloque_id: str
    celda_x: int
    celda_y: int
    celda_z: int
    tipo_particula_id: str
    temperatura: Decimal = Field(default=Decimal("20.0"))
    integridad: Decimal = Field(default=Decimal("1.0"), ge=0, le=1)
    carga_electrica: Decimal = Field(default=Decimal("0.0"), ge=-100, le=100)

class ParticulaCreate(ParticulaBase):
    pass

class Particula(ParticulaBase):
    id: str
    creado_en: datetime
    modificado_en: datetime
    
    class Config:
        from_attributes = True
```

**Notas:**
- Los modelos Pydantic proporcionan validación automática
- Usar Field con constraints apropiados
- **⚠️ READMEs:** Documentar modelos en `backend/src/models/README.md`

---

### Paso 9: Verificar Schema Inicial Completo

**Descripción:**
Verificar que el schema inicial (`01-init-schema.sql`) contiene todas las tablas y campos necesarios, y que el orden de creación es correcto (bloques antes de particulas).

**Archivos a modificar/crear:**
- `database/init/01-init-schema.sql` (verificar orden y completitud)

**Detalles de implementación:**
```bash
# Verificar que el schema se puede ejecutar sin errores
# Al reconstruir Docker, el schema debe crear todo desde cero

# Orden correcto de creación en schema:
# 1. Extensiones (uuid-ossp, pg_trgm)
# 2. Esquema (juego_dioses)
# 3. Tabla bloques (antes de particulas)
# 4. Tabla tipos_particulas (antes de particulas y transiciones)
# 5. Tabla particulas (depende de bloques y tipos_particulas)
# 6. Tabla transiciones_particulas (depende de tipos_particulas)
# 7. Índices
# 8. Comentarios

# Verificar estructura después de rebuild:
docker-compose exec postgres psql -U postgres -d juego_dioses -c "\d bloques"
docker-compose exec postgres psql -U postgres -d juego_dioses -c "\d particulas"
docker-compose exec postgres psql -U postgres -d juego_dioses -c "\d tipos_particulas"
docker-compose exec postgres psql -U postgres -d juego_dioses -c "\d transiciones_particulas"
```

**Notas:**
- ⚠️ **IMPORTANTE:** El orden de creación es crítico (bloques y tipos_particulas antes de particulas)
- Asegurar que todas las foreign keys estén correctamente definidas
- Verificar que no haya referencias a `dimensiones` en ningún lugar
- **⚠️ READMEs:** Documentar estructura del schema inicial

---

### Paso 10: Crear/Actualizar READMEs

**Descripción:**
Crear o actualizar READMEs para documentar los nuevos módulos, cambios en esquema y cómo usar las nuevas funcionalidades.

**Archivos a modificar/crear:**
- `backend/src/services/README.md` (crear/actualizar)
- `backend/src/models/README.md` (crear/actualizar)
- `database/README.md` (crear/actualizar)
- `database/migrations/README.md` (crear/actualizar)

---

### Paso 11: Corregir Breaking Changes (dimensiones → bloques)

**Descripción:**
Actualizar todas las rutas de API y código legacy para usar `bloques` en lugar de `dimensiones` en consultas SQL, manteniendo compatibilidad de API con el frontend.

**Archivos a modificar:**
- `backend/src/api/routes/dimensions.py` - Cambiar `dimensiones` → `bloques` en consultas SQL
- `backend/src/api/routes/particles.py` - Cambiar `dimension_id` → `bloque_id` en consultas SQL, mapear a `dimension_id` en SELECT
- `backend/src/api/routes/agrupaciones.py` - Cambiar `dimension_id` → `bloque_id` en consultas SQL, mapear a `dimension_id` en SELECT
- `backend/src/api/routes/characters.py` - Cambiar `dimension_id` → `bloque_id` en consultas SQL
- `backend/src/main.py` - Cambiar `dimensiones` → `bloques` en verificaciones de seeds

**Estrategia:**
- Mantener parámetros de API como `dimension_id` para compatibilidad con frontend
- Mapear `bloque_id` (BD) → `dimension_id` (API) en SELECT usando `AS dimension_id`
- Cambiar todas las consultas SQL para usar `bloques` y `bloque_id`

**Notas:**
- Los seeds (`seed_terrain_test_1.py`, `seed_terrain_test_2.py`, etc.) se corregirán en un ticket separado (JDG-039)
- Los modelos Pydantic antiguos (`schemas.py`) mantienen `dimension_id` por compatibilidad
- Ver `instructions/technical debt/02-breaking-changes-dimensiones-a-bloques.md` para detalles completos

**Detalles de implementación:**
Cada README debe incluir:
- Descripción del módulo/carpeta
- Estructura de archivos
- Componentes principales y responsabilidades
- Ejemplos de uso
- Referencias a documentación relacionada

**Notas:**
- Mantener documentación sincronizada con código
- Incluir ejemplos prácticos
- Referenciar documentos de diseño cuando sea apropiado

---

### Paso Final: Generar Descripción del Pull Request

**Descripción:**
Una vez completados todos los pasos anteriores y verificada la implementación, genera la descripción completa del Pull Request usando la regla `@pr-description.mdc`.

**Comando a ejecutar:**
```
@pr-description.mdc
```

**Resultado esperado:**
- Archivo generado: `JDG-038_pr-description_[FECHA-HORA].md` en `/instructions/prs/` (con fecha y hora obtenida de `Get-Date -Format "yyyy-MM-dd_HH-mm-ss"`)
- El archivo contendrá una descripción completa del PR lista para copiar y pegar en Git
- Incluirá: título, resumen, motivación, cambios técnicos, testing, referencias y riesgos

**Notas:**
- Este paso se ejecuta DESPUÉS de completar toda la implementación
- La descripción se genera automáticamente basándose en los cambios realizados
- El desarrollador solo necesita copiar y pegar el contenido en Git
- No editar manualmente a menos que sea estrictamente necesario

---

## Consideraciones Técnicas

### Performance
- Crear índices apropiados en todas las tablas para consultas frecuentes
- Usar índices parciales para optimizar consultas de partículas con propiedades anómalas
- Cache de configuraciones de bloques en memoria
- Lazy loading de bloques espaciales

### Seguridad
- Todas las consultas SQL deben ser parametrizadas
- Validación de entrada con Pydantic
- Verificar permisos de base de datos antes de ejecutar migraciones

### Casos Edge
- Partículas en coordenadas negativas o muy grandes
- Bloques con tamaño diferente al default
- Migración con datos existentes
- Partículas huérfanas (sin bloque válido)
- Bloques sin partículas

### Compatibilidad
- **⚠️ IMPORTANTE:** Al reconstruir Docker, se perderán todos los datos existentes
- El schema inicial debe crear todo desde cero sin necesidad de migraciones
- Verificar que no haya código que aún use `dimension_id` o `dimensiones`

## Patrones de Código a Usar

- **Backend (FastAPI)**: 
  - Modelos Pydantic para validación
  - async/await para operaciones I/O
  - Servicios organizados por responsabilidad
  - Docstrings en formato Google

- **Base de Datos**: 
  - asyncpg para conexiones asíncronas
  - Consultas parametrizadas
  - Índices apropiados para performance
  - Schema inicial completo (sin migraciones)

## Dependencias

### Nuevas Dependencias (si aplica)
```txt
# No se requieren nuevas dependencias
# Todas las librerías ya están en el proyecto
```

### Variables de Entorno (si aplica)
- `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB`: Ya configuradas

## Archivos Principales Involucrados

1. `database/init/01-init-schema.sql` - Esquema base completo (sin migraciones)
2. `backend/src/services/world_bloque.py` - Clase WorldBloque
3. `backend/src/services/world_bloque_manager.py` - Manager de bloques
4. `backend/src/services/particula_service.py` - Funciones auxiliares
5. `backend/src/models/particula_schemas.py` - Modelos Pydantic

## Testing

### Tests a Crear/Modificar
- Unit tests: `tests/test_world_bloque.py`
- Unit tests: `tests/test_world_bloque_manager.py`
- Unit tests: `tests/test_particula_service.py`
- Integration tests: `tests/integration/test_schema.py` (verificar schema inicial)

### Escenarios de Prueba
1. Reconstruir Docker y verificar que schema se crea correctamente
2. Crear tipo de partícula y verificar todos los campos nuevos
3. Crear partícula y asociarla con bloque (usando `bloque_id`)
4. Obtener bloque por posición y verificar cálculo correcto
5. Obtener partículas vecinas y verificar resultados
6. Verificar integridad referencial (foreign keys funcionan)
7. Verificar que no existen referencias a `dimensiones` o `dimension_id`

## Deployment

### Orden de Deployment
1. **Eliminar build de Docker:** `docker-compose down -v` (opcional: `-v` para limpiar volúmenes)
2. **Rebuild completo:** `docker-compose build --no-cache`
3. **Levantar servicios:** `docker-compose up -d`
4. **Verificar que schema se creó correctamente:** Verificar logs de PostgreSQL
5. **Verificar en ambiente local:** Probar endpoints y funcionalidad básica
6. **Verificar logs de Docker:** Sin errores de creación de tablas

### Verificación Post-Deployment
- [ ] Verificar que todas las tablas existen (`bloques`, `particulas`, `tipos_particulas`, `transiciones_particulas`)
- [ ] Verificar que `bloques` tiene campo `tamano_bloque`
- [ ] Verificar que `particulas` usa `bloque_id` (no `dimension_id`)
- [ ] Verificar que todos los campos nuevos existen (`integridad`, `carga_electrica`, `conductividad_electrica`, `magnetismo`)
- [ ] Verificar que índices fueron creados
- [ ] Verificar que foreign keys funcionan correctamente
- [ ] Verificar que funciones auxiliares retornan datos correctos
- [ ] Verificar logs de aplicación sin errores
- [ ] Verificar que no hay referencias a `dimensiones` en código o queries

---

**Nota Final:** Este plan debe ejecutarse paso a paso, verificando cada paso antes de continuar con el siguiente. Si encuentras problemas o necesitas clarificación, consulta con el equipo antes de proceder.

**⚠️ IMPORTANTE:** El último paso del plan SIEMPRE debe ser "Generar Descripción del Pull Request" usando `@pr-description.mdc`. Esto genera automáticamente la descripción completa del PR lista para Git.

