# JDG-045 - Sistema de Logging de Rendimiento (RAM, GPU, CPU)

## Tipo
- [x] Feature (nueva funcionalidad)
- [ ] Bugfix (corrección de error)
- [ ] Refactor (mejora de código sin cambiar funcionalidad)
- [ ] Performance (optimización)
- [ ] Documentation (documentación)
- [ ] Chore (tareas de mantenimiento)

## Prioridad
- [ ] Alta (bloquea funcionalidad crítica)
- [x] Media (importante pero no bloqueante)
- [ ] Baja (mejora o nice-to-have)

## Descripción

### Problema/Requerimiento

Actualmente no existe un sistema centralizado de logging de rendimiento que permita monitorear el consumo de recursos del sistema (RAM, GPU, CPU) tanto en backend como en frontend. Esto dificulta la identificación de problemas de rendimiento, memory leaks, y optimizaciones necesarias.

### Comportamiento Actual

**Backend:**
- No existe sistema de logging de rendimiento
- No se monitorean métricas de memoria, CPU, o conexiones de base de datos
- No hay visibilidad del estado del pool de conexiones de PostgreSQL

**Frontend:**
- Existe un sistema de debugger básico (`frontend/src/debug/metrics.js`) que mide frame time y tiempos de sistemas ECS
- No se monitorean métricas de memoria (heap, RSS)
- No se monitorean métricas de GPU
- No se monitorean métricas de CPU
- Las métricas existentes no se loguean de forma estructurada

### Comportamiento Esperado

**Backend:**
- Sistema de logging de rendimiento que registre periódicamente:
  - Memoria: RSS, heap total, heap usado
  - CPU: Load average (1m, 5m, 15m)
  - Base de datos: Total de conexiones, conexiones idle, requests en espera
  - Timestamp de cada log
- Formato de log estructurado (JSON) similar al ejemplo de NestJS
- Configuración de intervalo de logging (ej: cada 30 segundos)
- Logging a nivel DEBUG para no saturar logs en producción

**Frontend:**
- Extender el sistema de debugger existente para incluir:
  - Memoria: heap total, heap usado, heap limit
  - GPU: Información del renderer (si está disponible)
  - CPU: Información de performance (si está disponible)
  - Frame time (ya existe, pero mejorarlo)
- Integrar con el sistema de debugger existente (`frontend/src/debug/`)
- Mostrar métricas en la interfaz de debug (F6) si está habilitada
- Opción de logging a consola con formato estructurado

**Formato de Log Esperado (Backend):**
```
[Nest] 17 - 01/07/2026, 11:35:14 AM DEBUG [JsonStorageService] [RUNTIME STATS] {"timestamp":"2026-01-07T14:35:14.201Z","memory":{"rss":"174.06 MB","heapTotal":"97.20 MB","heapUsed":"92.29 MB"},"dbPool":{"totalConnections":1,"idleConnections":1,"waitingRequests":0},"cpu":{"loadAvg1m":"9.33"}}
```

## Contexto Técnico

### Componentes Afectados
- [x] Backend (FastAPI)
- [x] Frontend (Three.js)
- [ ] Base de Datos (PostgreSQL)
- [ ] Cache (Redis)
- [ ] Docker/Infraestructura
- [ ] API Endpoints

### Tecnologías Involucradas
- **Backend:**
  - Python 3.11, FastAPI
  - `psutil` (para métricas del sistema: memoria, CPU)
  - `asyncpg` (para métricas del pool de conexiones)
  - Logging estándar de Python (para formato estructurado)
- **Frontend:**
  - JavaScript ES6+
  - `performance.memory` API (para métricas de memoria)
  - `performance.getEntriesByType()` (para métricas de rendimiento)
  - Three.js Renderer info (para métricas de GPU)
  - Sistema de debugger existente (`frontend/src/debug/`)

### Archivos/Componentes Principales

**Backend:**
- `backend/src/services/performance_monitor_service.py` - Nuevo servicio para monitoreo
- `backend/src/config/performance_config.py` - Configuración de intervalos y niveles
- `backend/src/main.py` - Integrar servicio de monitoreo
- `backend/requirements.txt` - Agregar `psutil` si no está

**Frontend:**
- `frontend/src/debug/metrics.js` - Extender con métricas de RAM, GPU, CPU
- `frontend/src/debug/performance-logger.js` - Nuevo módulo para logging estructurado
- `frontend/src/interfaces/debug-interface.js` - Mostrar métricas en UI de debug
- `frontend/src/config/debug-config.js` - Configuración de logging de rendimiento

## Criterios de Aceptación

1. [ ] Backend loguea métricas de rendimiento periódicamente (configurable, default: cada 30 segundos)
2. [ ] Backend incluye métricas de memoria (RSS, heap total, heap usado) en formato legible (MB)
3. [ ] Backend incluye métricas de CPU (load average 1m)
4. [ ] Backend incluye métricas del pool de conexiones de PostgreSQL (total, idle, waiting)
5. [ ] Backend usa formato de log estructurado (JSON) similar al ejemplo de NestJS
6. [ ] Frontend extiende el sistema de debugger existente con métricas de memoria
7. [ ] Frontend incluye métricas de GPU (si están disponibles desde Three.js)
8. [ ] Frontend muestra métricas en la interfaz de debug (F6) cuando está habilitada
9. [ ] Frontend puede loguear métricas a consola con formato estructurado (opcional)
10. [ ] El sistema no degrada significativamente el rendimiento (< 1% de overhead)
11. [ ] Las métricas se pueden habilitar/deshabilitar mediante configuración

**Nota:** Cada criterio debe ser específico, medible y verificable.

## Detalles de Implementación

### Consideraciones Técnicas

**Backend:**
- Usar `psutil` para obtener métricas del sistema (memoria, CPU)
- Usar `asyncpg.Pool.get_stats()` para métricas del pool de conexiones
- Crear un servicio que se ejecute en background task (usando `asyncio.create_task`)
- Usar logging estándar de Python con nivel DEBUG
- Formatear memoria en MB para legibilidad
- Configurar intervalo de logging (default: 30 segundos)

**Frontend:**
- Extender `DebugMetrics` existente en `frontend/src/debug/metrics.js`
- Usar `performance.memory` API (puede no estar disponible en todos los navegadores)
- Usar `renderer.info` de Three.js para métricas de GPU
- Integrar con el sistema de debugger existente (no crear sistema paralelo)
- Mostrar métricas en la interfaz de debug existente (F6)
- Opción de logging a consola con formato JSON

**Performance:**
- El logging no debe ejecutarse en cada frame (solo periódicamente)
- Usar sampling para reducir overhead
- Las métricas deben ser opcionales y configurables

**Compatibilidad:**
- Backend debe funcionar sin `psutil` (fallback si no está disponible)
- Frontend debe funcionar si `performance.memory` no está disponible
- No romper funcionalidad existente del debugger

### Dependencias
- Depende de: Ninguno
- Bloquea: Posibles optimizaciones futuras basadas en métricas

## Testing

### Escenarios de Prueba

1. **Backend - Logging periódico:**
   - Verificar que el backend loguea métricas cada X segundos (configurable)
   - Verificar que el formato de log es correcto (JSON estructurado)
   - Verificar que incluye todas las métricas requeridas

2. **Backend - Métricas de memoria:**
   - Verificar que RSS, heap total y heap usado se muestran correctamente
   - Verificar que los valores están en MB y son legibles

3. **Backend - Métricas de CPU:**
   - Verificar que load average se muestra correctamente

4. **Backend - Métricas de DB pool:**
   - Verificar que total, idle y waiting connections se muestran correctamente

5. **Frontend - Métricas en debugger:**
   - Verificar que las métricas se muestran en la interfaz F6
   - Verificar que las métricas se actualizan periódicamente
   - Verificar que no degrada el rendimiento del juego

6. **Frontend - Métricas de memoria:**
   - Verificar que heap total, heap usado se muestran correctamente
   - Verificar que funciona aunque `performance.memory` no esté disponible

7. **Frontend - Métricas de GPU:**
   - Verificar que información del renderer se muestra (si está disponible)

8. **Configuración:**
   - Verificar que se puede habilitar/deshabilitar mediante configuración
   - Verificar que el intervalo es configurable

### Casos Edge a Considerar

- **Navegadores sin `performance.memory`:** El sistema debe funcionar sin estas métricas
- **Sistema sin `psutil`:** Backend debe funcionar con fallback o mensaje de advertencia
- **Alto volumen de logs:** El logging no debe saturar los logs en producción
- **Overhead de performance:** El sistema no debe degradar significativamente el rendimiento

## Estimación

- **Complejidad:** Media
- **Tiempo estimado:** 6-8 horas
- **Notas:** 
  - La implementación del backend es relativamente directa con `psutil`
  - La integración con el frontend requiere extender el sistema existente sin romperlo
  - Se recomienda implementar primero el backend y luego el frontend

## Referencias

- **Relacionado con:** JDG-030 (Sistema de Debugging y Herramientas de Desarrollo)
- **Documentación relevante:**
  - `psutil` Python library: https://psutil.readthedocs.io/
  - `performance.memory` API: https://developer.mozilla.org/en-US/docs/Web/API/Performance/memory
  - Three.js Renderer Info: https://threejs.org/docs/#api/en/renderers/WebGLRenderer
  - Sistema de debugger existente: `frontend/src/debug/README.md`
- **Ejemplo de log:** Formato similar a NestJS mostrado en la descripción

## Notas Adicionales

- **Integración con sistema existente:** Es importante extender el sistema de debugger del frontend en lugar de crear uno nuevo
- **Configuración:** Las métricas deben ser configurables para no afectar producción
- **Formato de log:** El formato debe ser consistente entre backend y frontend para facilitar análisis
- **Overhead:** El sistema debe tener mínimo overhead para no afectar el rendimiento del juego
- **Compatibilidad:** El sistema debe funcionar aunque algunas APIs no estén disponibles
